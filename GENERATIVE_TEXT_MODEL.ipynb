{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521,
     "referenced_widgets": [
      "ab4219ecc051430c91de33121b083b5d",
      "486d808b8a2a40c3b6707cc5b10f9b25",
      "0ffdaad075b343bba08f5c0f191bcf72",
      "43dd3d1df36345aab21d7e429534ba28",
      "5fc1aa9dd9994df5bc16c921f49bbb4e",
      "d97ec191109746478e3cb5ab33e6b44a",
      "68fb6cfba1c24cf6999e218a0b6f5073",
      "d13ccbb53b5b4170ba70020e4d0bf836",
      "d90502a626014e99a8599605ca1117fc",
      "5b3833c9b828428a882bdd90f804de56",
      "fbf281b8937c447db744e6bce7b3537a",
      "5ae3cdc42a074930bd5ac9f175d7067e",
      "5fd72eac6ad443cc8e9ee32b6dddb1b3",
      "4a75bb8509fb4c1ea537c8bf1e3785fa",
      "909d25dc68754ed6b3f4b1743582400e",
      "4444f58275a941de81fa72d6342d1730",
      "16ad1baa9332462a94d3852176add3bd",
      "47dfe3e833e0417b99b196f1374417bd",
      "e6e49e7cc6ea42cc9910d61f67a52ff7",
      "1d9c26d3875448a99963d55436f69cec",
      "75a5b9a2a20743c7a2e20552a228ce9d",
      "a85f8b4f73e4437098598dd093ea9114",
      "7f13a300f1094c05979cd91ae27cf4c8",
      "bf2e4ea39e46460a9e1e199d7d9d41b9",
      "ef330cb4ef73400bac562a743b8259ab",
      "b58a6b0500da45ad8532280a2aad052b",
      "df9742e9d950401aa36d45decb7e0653",
      "d553d4cd338744f8b184056bbe4d9715",
      "4b5e950aa2e2473aa8093e259dfe2bff",
      "d70c06db04574538990305ec6325344e",
      "4c345bbf366345d7be9b91a712a0b0a0",
      "68d83990d5244e4d961ebe30a496ee08",
      "9b249cf46e044ae7baa7c93bd1886055",
      "73d82801a1674b1f928a29cf84618877",
      "be1bb838a7d64dfab06677c5ce712cbd",
      "6dd8361e7b7142a1b3510df0ba0abd5b",
      "27f48a919aef4393b40146867f818a5e",
      "bedc41c25e24439b8b8717c61ea96e6c",
      "5daf15746df84350b5d800c7dc93231a",
      "406563535d87463eb1d0e763daf62e67",
      "1276bb07dbf048b3831136848c0773df",
      "d3e613950e414b1b887fdc1f60a48fdb",
      "61e4a00a97f5417b8423a500f54aa8e0",
      "46b5453255e04ef68128c74d72d714e6",
      "49968921345645cebb3c6fde91cc3891",
      "554409b0dbe14f0b906cec52f7f5f1db",
      "c8771aeb0bdd420ca94170c5f908f13c",
      "2ecb2bb7193a46d9b8e4f2c130ef840f",
      "4a650f69703d4a8fb3c2f0600ec68cee",
      "c14bde8c532f428e9a3a892fd029ec56",
      "e4d0ec19073f415c8f09418af59ebb9e",
      "b6773182782643248f824b0c72e0f77c",
      "81d326ff182c424d9fbf13b2bf64e751",
      "e896d37b7af949f6b55939a5be777957",
      "5a1e389a00134dc0906980086a78ae3e",
      "1f551018b685453cb247405950c6579f",
      "2cf5ffff50a945f7a27e550ac6bd4378",
      "f89382dc3def42f3b292b7a9e74faad7",
      "5312845e49b6474bad4e79f160ab3df9",
      "adea44b69e3048fe93c3201422b12549",
      "a52f0b44f36748c997c90f5b213b69f6",
      "f2d85f7c02214bbfa95e6190b86089ad",
      "3215b49497824b8e9900c403c0179b4f",
      "85f501c6f68f45a7964aee5a0285a493",
      "cf5463c71e8e4706a9d0fe9926cbdf61",
      "f065c17406a842c49bb2f1370ecb030d"
     ]
    },
    "id": "X4rp7SnMKuXf",
    "outputId": "9172736b-851e-4f84-f756-82ccad589a56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a topic or prompt: \"Discuss the impact of social media on mental health.\"\n",
      "Enter creativity (temperature, 0.0 to 1.0): 0.5\n",
      "Enter max length for generated text: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      "\n",
      "\"Discuss the impact of social media on mental health.\" \"The impact on the mental well-being of the young and the elderly.\" \"\"The Impact of Social Media on Mental Health\".\" \"...and the social impact.\" \"(SIGHS)\" \"I'm going to be honest with you.\" \"'Cause I'm not going anywhere.\" \"[SINGING] I've got a lot of friends\" \"And I don't want to lose them\" \"'cause I know they're there\" \"[CH\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load pre-trained GPT-Neo 1.3B model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "def generate_text(prompt, temperature=0.7, max_length=150):\n",
    "    # Tokenize input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate text from the model\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "\n",
    "    # Decode the output tokens to text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Input prompt from the user\n",
    "prompt = input(\"Enter a topic or prompt: \")\n",
    "\n",
    "# Optional parameters (can be adjusted)\n",
    "temperature = float(input(\"Enter creativity (temperature, 0.0 to 1.0): \"))\n",
    "max_length = int(input(\"Enter max length for generated text: \"))\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(prompt, temperature, max_length)\n",
    "\n",
    "# Display the generated text\n",
    "print(\"\\nGenerated Text:\\n\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cN8x_3PsKwD3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
